{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05760ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate manual annotation of positive/negative marker (x,y positions)\n",
    "# to single cells\n",
    "# Run training using CellSighter\n",
    "# authors: Pacome Prompsy\n",
    "# contact: pacome.prompsy@chuv.ch\n",
    "# Guenova Lab\n",
    "# CHUV (Centre Hospitalier Universitaire Vaudois), Lausanne, Suisse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e5d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "import random\n",
    "import cv2\n",
    "import tifffile\n",
    "from scipy.spatial.distance import cdist\n",
    "import re\n",
    "import fileinput\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3273b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e2f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../output/CellSighter/marker\"\n",
    "marker_file  = \"../annotation/marker_metadata_old.csv\"\n",
    "tiff_dir = \"../output/input/\"\n",
    "segmentation_dir  = \"../output/segmentation/\"\n",
    "cell_table_dir  = \"../output/cell_table/\"\n",
    "config_file = \"../output/CellSighter/marker/marker_classification/config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c00120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_df = pd.read_csv(os.path.join(marker_file))\n",
    "\n",
    "marker_unique = marker_df.Marker[marker_df.PassOverallQuality == True]\n",
    "marker_unique = marker_unique[marker_unique != \"DAPI\"]\n",
    "marker_unique = marker_unique.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefbfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\"ROI-01\", \"ROI-10\", \"ROI-20\", \"ROI-30\", \"ROI-40\", \"ROI-50\", \"ROI-60\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b322aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e2c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(annotation_dir, name, marker + \"+.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d971787",
   "metadata": {},
   "outputs": [],
   "source": [
    "for marker in [\"CD4\"]:\n",
    "    print(marker)\n",
    "    for sample in samples:\n",
    "\n",
    "        print(sample)\n",
    "        annotator = \"Annotator1\"\n",
    "        if len(annotator) > 0:\n",
    "            name = sample + \"-\" + annotator\n",
    "        else:\n",
    "            name = sample\n",
    "        annotation_dir = \"../output/manual_annotation_marker2/\" + name\n",
    "\n",
    "\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        base_dir = os.path.join(output_dir, \"marker_classification\")\n",
    "        if not os.path.exists(base_dir):\n",
    "            os.makedirs(base_dir)\n",
    "        \n",
    "        if os.path.isfile( os.path.join(annotation_dir, marker + \"+.csv\")):\n",
    "        \n",
    "            marker_dir = os.path.join(base_dir, marker)\n",
    "            if not os.path.exists(marker_dir):\n",
    "                os.makedirs(marker_dir)\n",
    "\n",
    "            celltypes_dir = os.path.join(marker_dir, \"CellTypes\")\n",
    "            if not os.path.exists(celltypes_dir):\n",
    "                os.makedirs(celltypes_dir)\n",
    "\n",
    "            cells_dir = os.path.join(celltypes_dir, \"cells\")\n",
    "            if not os.path.exists(cells_dir):\n",
    "                os.makedirs(cells_dir)\n",
    "            cells2labels_dir = os.path.join(celltypes_dir, \"cells2labels\")\n",
    "            if not os.path.exists(cells2labels_dir):\n",
    "                os.makedirs(cells2labels_dir)\n",
    "            data_dir = os.path.join(celltypes_dir, \"data\")\n",
    "            if not os.path.exists(data_dir):\n",
    "                os.makedirs(data_dir)\n",
    "            images_dir =  os.path.join(data_dir, \"images\")\n",
    "            if not os.path.exists(images_dir):\n",
    "                os.makedirs(images_dir)    \n",
    "\n",
    "            # Load segmentation \n",
    "            whole_cell = imread(os.path.join(segmentation_dir, sample + \"_whole_cell.tiff\"))\n",
    "            # Save in the \"cells\" folder\n",
    "            np.savez(os.path.join(cells_dir, name +\".npz\"), data = whole_cell)\n",
    "\n",
    "            # Load the labels\n",
    "            csv_files = [marker + \"+.csv\", marker + \"-.csv\"]\n",
    "            dfs = []\n",
    "            for csv_file in csv_files:\n",
    "                # Read the CSV file into a dataframe\n",
    "                df = pd.read_csv(os.path.join(annotation_dir, csv_file))\n",
    "\n",
    "                # Get the cell type from the file name\n",
    "                cell_type = os.path.basename(csv_file).split('.csv')[0]\n",
    "                cell_type = re.sub(marker,\"\",cell_type)\n",
    "                if cell_type == \"+\":\n",
    "                    cell_type = 1\n",
    "                if cell_type == \"-\":\n",
    "                    cell_type = 0\n",
    "                # Add a column for the cell type\n",
    "                df['class'] = cell_type\n",
    "\n",
    "                # Append the dataframe to the list of dataframes\n",
    "                dfs.append(df)\n",
    "            result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "            # Reading the cell centroids\n",
    "            cells = pd.read_csv(os.path.join(cell_table_dir, sample + \"_cell_table_size_normalized.csv.gz\"))\n",
    "            cells = cells[['centroid-0', 'centroid-1', 'label']]\n",
    "            cells[\"class\"] = -1\n",
    "\n",
    "            # Loop through each cell in the \"cells\" dataframe\n",
    "            for i, row in result_df.iterrows():\n",
    "                # Extract the x and y coordinates of the cell centroid\n",
    "                point_x, point_y, cell_class = row[\"axis-0\"], row[\"axis-1\"], row[\"class\"]\n",
    "\n",
    "                # Initialize a dictionary to store the distances to the closest point in each cell type\n",
    "                distances = {}\n",
    "\n",
    "                # Loop through each cell type in the \"result_df\" dataframe\n",
    "\n",
    "                # Filter the \"result_df\" dataframe to include only the points for the current cell type\n",
    "                cells_locations = cells[['centroid-0', 'centroid-1', 'label']].values\n",
    "                cells_locations = cells_locations[((cells_locations[...,0] > point_x - 200) & (cells_locations[...,0] < point_x + 200)) &\n",
    "                                         ((cells_locations[...,1] > point_y - 200) & (cells_locations[...,1] < point_y + 200))]\n",
    "\n",
    "                if cells_locations.shape[0] > 0:\n",
    "                    # Compute the distances from the cell centroid to each point in the filtered dataframe\n",
    "                    cell_distances = cdist([[point_x, point_y]], cells_locations[...,0:2]).flatten()\n",
    "                    label = cells_locations[np.where(cell_distances==np.min(cell_distances))[0][0],2]\n",
    "\n",
    "                    # Add the closest cell type\n",
    "                    if np.min(cell_distances) < 150: \n",
    "                        cells.loc[(cells.label == label),\"class\"] = cell_class\n",
    "\n",
    "            labels = np.zeros(int(max(cells.label)) + 1)\n",
    "            for i in range(len(labels)):\n",
    "                labels[i] = -1\n",
    "            idx = [int(item) for item in cells[\"label\"].to_list()]\n",
    "            labels[idx] = cells[\"class\"]\n",
    "\n",
    "            # Save as npz in the \"data\" folder\n",
    "            np.savez(os.path.join(cells2labels_dir,  name + \".npz\"), data = labels)\n",
    "\n",
    "\n",
    "            all_markers = []\n",
    "            # Load the markers \n",
    "            for mark in [marker, \"DAPI\"]:\n",
    "                # Load segmentation \n",
    "                marker_image = imread(os.path.join(tiff_dir, sample, mark + \".tiff\"))\n",
    "\n",
    "                # Save in the \"cells\" folder\n",
    "                all_markers.append(marker_image)\n",
    "\n",
    "\n",
    "            # Combine\n",
    "            all_markers = np.array(all_markers)\n",
    "            all_markers = np.transpose(all_markers, (1, 2, 0))\n",
    "\n",
    "            # Save as npz in the \"data\" folder\n",
    "\n",
    "            np.savez(os.path.join(images_dir,  name + \".npz\"),  data = all_markers)\n",
    "\n",
    "            with open(os.path.join(marker_dir, 'channels.txt'), 'w') as f:\n",
    "                f.write(marker + \"\\n\")\n",
    "                f.write('DAPI')\n",
    "\n",
    "            channel = os.path.join(marker_dir, 'channels.txt')\n",
    "            shutil.copyfile(config_file, os.path.join(marker_dir, \"config.json\"))\n",
    "            with fileinput.FileInput(os.path.join(marker_dir, \"config.json\"), inplace=True) as file:\n",
    "                for line in file:\n",
    "                    print(line.replace(\"XXXX\", \"output/CellSighter/marker/marker_classification/\" + marker), end='')\n",
    "            with fileinput.FileInput(os.path.join(marker_dir, \"config.json\"), inplace=True) as file:\n",
    "                for line in file:\n",
    "                    print(line.replace(\"YYYY\",\"output/CellSighter/marker/marker_classification/\" + marker + \"/\" + \"channels.txt\"), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(marker_dir, \"channels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e7ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c7efb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

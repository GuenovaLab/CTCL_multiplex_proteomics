{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef837d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate manual annotation of celltypes (x,y positions)\n",
    "# to single cells\n",
    "# authors: Pacome Prompsy\n",
    "# contact: pacome.prompsy@chuv.ch\n",
    "# Guenova Lab\n",
    "# CHUV (Centre Hospitalier Universitaire Vaudois), Lausanne, Suisse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "import random\n",
    "import cv2\n",
    "import tifffile\n",
    "from scipy.spatial.distance import cdist\n",
    "import re\n",
    "import fileinput\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../output/CellSighter/marker/\"\n",
    "training_dir = \"../output/CellSighter/marker/marker_classification/\"\n",
    "marker_file  = \"../annotation/marker_metadata.csv\"\n",
    "tiff_dir = \"../output/input/\"\n",
    "segmentation_dir  = \"../output/segmentation/\"\n",
    "cell_table_dir  = \"../output/cell_table/\"\n",
    "config_file = \"../output/CellSighter/marker/Predictions/config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edea86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543e5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_df = pd.read_csv(os.path.join(marker_file))\n",
    "\n",
    "marker_unique = marker_df.Marker[marker_df.PassOverallQuality == True]\n",
    "marker_unique = marker_unique[marker_unique != \"DAPI\"]\n",
    "marker_unique = marker_unique.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d875804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in os.listdir(tiff_dir)[63:68]:\n",
    "    print(sample)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    base_dir = os.path.join(output_dir, \"Predictions\")\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "\n",
    "    print(sample)\n",
    "    annotator = \"\"\n",
    "    if len(annotator) > 0:\n",
    "        name = sample + \"-\" + annotator\n",
    "    else:\n",
    "        name = sample\n",
    "\n",
    "    annotation_dir = \"../output/manual_annotation_marker/\" + name\n",
    "\n",
    "    for marker in marker_unique:\n",
    "        print(marker)\n",
    "        marker_dir = os.path.join(base_dir, marker)\n",
    "        if not os.path.exists(marker_dir):\n",
    "            os.makedirs(marker_dir)\n",
    "\n",
    "        celltypes_dir = os.path.join(marker_dir, \"CellTypes\")\n",
    "        if not os.path.exists(celltypes_dir):\n",
    "            os.makedirs(celltypes_dir)\n",
    "\n",
    "        cells_dir = os.path.join(celltypes_dir, \"cells\")\n",
    "        if not os.path.exists(cells_dir):\n",
    "            os.makedirs(cells_dir)\n",
    "        cells2labels_dir = os.path.join(celltypes_dir, \"cells2labels\")\n",
    "        if not os.path.exists(cells2labels_dir):\n",
    "            os.makedirs(cells2labels_dir)\n",
    "        data_dir = os.path.join(celltypes_dir, \"data\")\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)\n",
    "        images_dir =  os.path.join(data_dir, \"images\")\n",
    "        if not os.path.exists(images_dir):\n",
    "            os.makedirs(images_dir)    \n",
    "\n",
    "        if os.path.isfile(os.path.join(tiff_dir, sample, marker + \".tiff\")):\n",
    "    \n",
    "            # Load segmentation \n",
    "            whole_cell = imread(os.path.join(segmentation_dir, sample + \"_whole_cell.tiff\"))\n",
    "            # Save in the \"cells\" folder\n",
    "            np.savez(os.path.join(cells_dir, name +\".npz\"), data = whole_cell)\n",
    "\n",
    "\n",
    "            if annotator == \"\":\n",
    "\n",
    "                # Reading the cell centroids\n",
    "                cells = pd.read_csv(os.path.join(cell_table_dir, sample + \"_cell_table_size_normalized.csv.gz\"))\n",
    "                cells = cells[['centroid-0', 'centroid-1', 'label']]\n",
    "\n",
    "                labels = np.zeros(int(max(cells.label)) + 1)\n",
    "                for i in range(len(labels)):\n",
    "                    labels[i] = -1\n",
    "\n",
    "                # Save as npz in the \"data\" folder\n",
    "                np.savez(os.path.join(cells2labels_dir,  name + \".npz\"), data = labels)\n",
    "\n",
    "            else:\n",
    "                # Load the labels\n",
    "                csv_files = [marker + \"+.csv\", marker + \"-.csv\"]\n",
    "                dfs = []\n",
    "                for csv_file in csv_files:\n",
    "                    # Read the CSV file into a dataframe\n",
    "                    df = pd.read_csv(os.path.join(annotation_dir, csv_file))\n",
    "\n",
    "                    # Get the cell type from the file name\n",
    "                    cell_type = os.path.basename(csv_file).split('.csv')[0]\n",
    "                    cell_type = re.sub(marker,\"\",cell_type)\n",
    "                    if cell_type == \"+\":\n",
    "                        cell_type = 1\n",
    "                    if cell_type == \"-\":\n",
    "                        cell_type = 0\n",
    "                    # Add a column for the cell type\n",
    "                    df['class'] = cell_type\n",
    "\n",
    "                    # Append the dataframe to the list of dataframes\n",
    "                    dfs.append(df)\n",
    "                result_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "                # Reading the cell centroids\n",
    "                cells = pd.read_csv(os.path.join(cell_table_dir, sample + \"_cell_table_size_normalized.csv.gz\"))\n",
    "                cells = cells[['centroid-0', 'centroid-1', 'label']]\n",
    "                cells[\"class\"] = -1\n",
    "\n",
    "                # Loop through each cell in the \"cells\" dataframe\n",
    "                for i, row in result_df.iterrows():\n",
    "                    # Extract the x and y coordinates of the cell centroid\n",
    "                    point_x, point_y, cell_class = row[\"axis-0\"], row[\"axis-1\"], row[\"class\"]\n",
    "\n",
    "                    # Initialize a dictionary to store the distances to the closest point in each cell type\n",
    "                    distances = {}\n",
    "\n",
    "                    # Loop through each cell type in the \"result_df\" dataframe\n",
    "\n",
    "                    # Filter the \"result_df\" dataframe to include only the points for the current cell type\n",
    "                    cells_locations = cells[['centroid-0', 'centroid-1', 'label']].values\n",
    "                    cells_locations = cells_locations[((cells_locations[...,0] > point_x - 200) & (cells_locations[...,0] < point_x + 200)) &\n",
    "                                             ((cells_locations[...,1] > point_y - 200) & (cells_locations[...,1] < point_y + 200))]\n",
    "\n",
    "                    if cells_locations.shape[0] > 0:\n",
    "                        # Compute the distances from the cell centroid to each point in the filtered dataframe\n",
    "                        cell_distances = cdist([[point_x, point_y]], cells_locations[...,0:2]).flatten()\n",
    "                        label = cells_locations[np.where(cell_distances==np.min(cell_distances))[0][0],2]\n",
    "\n",
    "                        # Add the closest cell type\n",
    "                        if np.min(cell_distances) < 150: \n",
    "                            cells.loc[(cells.label == label),\"class\"] = cell_class\n",
    "\n",
    "                labels = np.zeros(int(max(cells.label)) + 1)\n",
    "                for i in range(len(labels)):\n",
    "                    labels[i] = -1\n",
    "                idx = [int(item) for item in cells[\"label\"].to_list()]\n",
    "                labels[idx] = cells[\"class\"]\n",
    "\n",
    "                # Save as npz in the \"data\" folder\n",
    "                np.savez(os.path.join(cells2labels_dir,  name + \".npz\"), data = labels)\n",
    "\n",
    "\n",
    "            # Copy full markers images\n",
    "\n",
    "            all_markers = []\n",
    "\n",
    "            # Load the markers \n",
    "            for mark in [marker, \"DAPI\"]:\n",
    "\n",
    "                # Load segmentation \n",
    "                marker_image = imread(os.path.join(tiff_dir, sample, mark + \".tiff\"))\n",
    "\n",
    "                # Save in the \"cells\" folder\n",
    "                all_markers.append(marker_image)\n",
    "\n",
    "\n",
    "            # Combine\n",
    "            all_markers = np.array(all_markers)\n",
    "            all_markers = np.transpose(all_markers, (1, 2, 0))\n",
    "\n",
    "            # Save as npz in the \"data\" folder\n",
    "\n",
    "            np.savez(os.path.join(images_dir,  name + \".npz\"),  data = all_markers)\n",
    "\n",
    "            with open(os.path.join(marker_dir, 'channels.txt'), 'w') as f:\n",
    "                f.write(marker + \"\\n\")\n",
    "                f.write('DAPI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel classification using Pixie\n",
    "# authors: Pacome Prompsy\n",
    "# contact: pacome.prompsy@chuv.ch\n",
    "# Guenova Lab\n",
    "# CHUV (Centre Hospitalier Universitaire Vaudois), Lausanne, Suisse\n",
    "\n",
    "# Scripts adapted from ARK analysis pipeline:\n",
    "# https://github.com/angelolab/ark-analysis\n",
    "#\n",
    "# Greenwald, N.F., Miller, G., Moen, E. et al. Whole-cell segmentation of tissue \n",
    "# images with human-level performance using large-scale data annotation and deep learning.\n",
    "# Nat Biotechnol 40, 555â€“565 (2022). https://doi.org/10.1038/s41587-021-01094-0\n",
    "#\n",
    "# Liu, C.C., Greenwald, N.F., Kong, A. et al. Robust phenotyping of highly multiplexed\n",
    "# tissue imaging data using pixel-level clustering. Nat Commun 14, 4618 (2023).\n",
    "# https://doi.org/10.1038/s41467-023-40068-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b955a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import json, os, re, argparse, feather\n",
    "from typing import List\n",
    "from skimage.io import imread\n",
    "from alpineer import image_utils, io_utils, load_utils, misc_utils\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "from typing import List, Union\n",
    "from PIL import Image\n",
    "\n",
    "import feather\n",
    "import natsort as ns\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from ark.utils import data_utils\n",
    "from ark import settings\n",
    "\n",
    "###############################################################################\n",
    "## Multiplexing util functions\n",
    "###############################################################################\n",
    "\n",
    "def read_markers(marker_file):\n",
    "    with open(marker_file, \"r\") as fp:\n",
    "         lines = fp.readlines()\n",
    "    markers = []\n",
    "    for l in lines:\n",
    "        markers.append(l.replace(\"\\n\", \"\"))\n",
    "    return(markers)\n",
    "    \n",
    "def qiSettings_to_markers(qiSettings_file):\n",
    "    \"\"\"\n",
    "    Create input links correctly named and create output directory structure.\n",
    "    Returns the new input directory containing links to TIFF files.\n",
    "    \"\"\"\n",
    "    f = open(qiSettings_file)\n",
    "    data = json.load(f)\n",
    "    markers = []\n",
    "    for item in data['data']:\n",
    "        markers.append(item['comparisonData']['dye'].replace(\" \", \"\"))\n",
    "    return markers\n",
    "\n",
    "def initialize_input(input_dir, output_dir, sample_name, markers):\n",
    "    \"\"\"\n",
    "    Create input links correctly named and create output directory structure.\n",
    "    Returns the new input directory containing links to TIFF files.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    tiffdir = os.path.join(output_dir, \"input\", sample_name)\n",
    "    if not os.path.exists(tiffdir):\n",
    "        os.makedirs(tiffdir)\n",
    "            \n",
    "    TIFFs = os.listdir(os.path.join(input_dir, sample_name))\n",
    "    links = dict.fromkeys(markers, \"\")\n",
    "\n",
    "    for file in TIFFs:\n",
    "        for marker in markers:\n",
    "            if marker == \"DAPI\" or marker == \"TRBC1\":\n",
    "                regex = re.compile(\".*\" + sample_name + \".*-\"  + marker + \".*.tif.*\")\n",
    "            else:\n",
    "                regex = re.compile(\".*\" + sample_name + \".*-\"  + marker + \"_.*.tif.*\")\n",
    "            \n",
    "            if regex.match(file):\n",
    "                links[marker] = file\n",
    "                \n",
    "    widthsX = dict()\n",
    "    heigthY = dict()\n",
    "    for marker in links:\n",
    "        url = os.path.join(input_dir, sample_name, links[marker])\n",
    "        img = Image.open(url)\n",
    "        widthsX[marker] = int(img.size[0])\n",
    "        heigthY [marker] = int(img.size[1])\n",
    "        \n",
    "    final_width = min(widthsX.values())\n",
    "    final_heigth = min(heigthY.values())\n",
    "    print(\"Final Width = \")\n",
    "    print(final_width)\n",
    "    \n",
    "    print(\"Final Heigth = \")\n",
    "    print(final_heigth)\n",
    "    \n",
    "    for marker in links:\n",
    "        if not os.path.exists(os.path.join(tiffdir, marker + \".tiff\")):\n",
    "            print(marker)\n",
    "            url = os.path.join(input_dir, sample_name, links[marker])\n",
    "            img = Image.open(url)\n",
    "             \n",
    "            startx = img.size[0] - final_width\n",
    "            starty = 0\n",
    "            stopx = img.size[0]\n",
    "            stopy = final_heigth\n",
    "        \n",
    "            img_cropped = img.crop((startx, starty, stopx, stopy))\n",
    "            img_cropped.save(os.path.join(tiffdir, marker + '.tiff'))\n",
    "\n",
    "    return os.path.join(output_dir, \"input\") \n",
    "\n",
    "###############################################################################\n",
    "## General util functions\n",
    "###############################################################################\n",
    "\n",
    "def dir_path(string):\n",
    "    if os.path.isdir(string):\n",
    "        return string\n",
    "    else:\n",
    "        raise NotADirectoryError(string)\n",
    "\n",
    "\n",
    "def parse_var(s):\n",
    "    \"\"\"\n",
    "    Parse a key, value pair, separated by '='\n",
    "    That's the reverse of ShellArgs.\n",
    "\n",
    "    On the command line (argparse) a declaration will typically look like:\n",
    "        foo=hello\n",
    "    or\n",
    "        foo=\"hello world\"\n",
    "    \"\"\"\n",
    "    items = s.split('=')\n",
    "    key = items[0].strip() # we remove blanks around keys, as is logical\n",
    "    if len(items) > 1:\n",
    "        # rejoin the rest:\n",
    "        value = '='.join(items[1:])\n",
    "    return (key, value)\n",
    "\n",
    "\n",
    "\n",
    "def parse_vars(items, to = \"int\"):\n",
    "    \"\"\"\n",
    "    Parse a series of key-value pairs and return a dictionary\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "\n",
    "    if items:\n",
    "        for item in items:\n",
    "            key, value = parse_var(item)\n",
    "            if to == \"int\":\n",
    "                d[key] = int(value)\n",
    "            elif to == \"float\":\n",
    "                d[key] = float(value)\n",
    "            elif to == \"bool\":\n",
    "                d[key] = value == 'True'\n",
    "            elif to == \"str\":\n",
    "                d[key] = str(value)\n",
    "            else :\n",
    "                d[key] = value\n",
    "    return d\n",
    "\n",
    "\n",
    "def filter_with_nuclear_mask(fovs: List, tiff_dir: str, seg_dir: str, channel: str,\n",
    "                             nuc_seg_suffix: str = \"_nuclear.tiff\", img_sub_folder: str = None,\n",
    "                             exclude: bool = True):\n",
    "    \"\"\"\n",
    "    Filters out background staining using subcellular marker localization.\n",
    "\n",
    "    Non-nuclear signal is removed from nuclear markers and vice-versa for membrane markers.\n",
    "\n",
    "    Args:\n",
    "        fovs (list):\n",
    "            The list of fovs to filter\n",
    "        tiff_dir (str):\n",
    "            Name of the directory containing the tiff files\n",
    "        seg_dir (str):\n",
    "            Name of the directory containing the segmented files\n",
    "        channel (str):\n",
    "            Channel to apply filtering to\n",
    "        nuc_seg_suffix (str):\n",
    "            The suffix for the nuclear channel.\n",
    "            (i.e. for \"fov1\", a suffix of \"_nuclear.tiff\" would make a file named\n",
    "            \"fov1_nuclear.tiff\")\n",
    "        img_sub_folder (str):\n",
    "            Name of the subdirectory inside `tiff_dir` containing the tiff files.\n",
    "            Set to `None` if there isn't any.\n",
    "        exclude (bool):\n",
    "            Whether to filter out nuclear or membrane signal\n",
    "    \"\"\"\n",
    "    # if seg_dir is None, the user cannot run filtering\n",
    "    if seg_dir is None:\n",
    "        print('No seg_dir provided, you must provide one to run nuclear filtering')\n",
    "        return\n",
    "\n",
    "    # raise an error if the provided seg_dir does not exist\n",
    "    io_utils.validate_paths(seg_dir)\n",
    "\n",
    "    # convert to path-compatible format\n",
    "    if img_sub_folder is None:\n",
    "        img_sub_folder = ''\n",
    "\n",
    "    for fov in fovs:\n",
    "        # load the channel image in\n",
    "        img = load_utils.load_imgs_from_tree(data_dir=tiff_dir, img_sub_folder=img_sub_folder,\n",
    "                                             fovs=[fov], channels=[channel]).values[0, :, :, 0]\n",
    "\n",
    "        # load the segmented image in\n",
    "        seg_img_name: str = f\"{fov}{nuc_seg_suffix}\"\n",
    "        seg_img = imread(os.path.join(seg_dir, seg_img_name))\n",
    "\n",
    "        # mask out the nucleus\n",
    "        if exclude:\n",
    "            suffix = \"_nuc_exclude.tiff\"\n",
    "            seg_mask = seg_img > 0\n",
    "        # mask out the membrane\n",
    "        else:\n",
    "            suffix = \"_nuc_include.tiff\"\n",
    "            seg_mask = seg_img == 0\n",
    "\n",
    "        # filter out the nucleus or membrane depending on exclude parameter\n",
    "        img[seg_mask] = 0\n",
    "\n",
    "        # save filtered image\n",
    "        image_utils.save_image(os.path.join(tiff_dir, fov, img_sub_folder, channel + suffix), img)\n",
    "        return\n",
    "\n",
    "# define the cell table path\n",
    "def combine_cell_tables(cell_table_dir, samples, cell_table_prefix = \"cell_table_size_normalized\"):\n",
    "    \"\"\"\n",
    "    Combine multiple single-fov matrices into a large matrix    \n",
    "    \"\"\"\n",
    "    cell_table = []\n",
    "\n",
    "    for samp in samples:\n",
    "        df = pd.read_csv(os.path.join(cell_table_dir, samp + \"_\" + cell_table_prefix + \".csv.gz\"))\n",
    "        cell_table.append(df)\n",
    "    \n",
    "    cell_table = pd.concat(cell_table, axis=0)\n",
    "    cell_table_path = os.path.join(cell_table_dir, cell_table_prefix + \".csv.gz\")\n",
    "    cell_table.to_csv(cell_table_path)\n",
    "    return(cell_table_path)\n",
    "    \n",
    "\n",
    "def generate_and_save_pixel_cluster_masks(fovs: List[str],\n",
    "                                          base_dir: Union[pathlib.Path, str],\n",
    "                                          save_dir: Union[pathlib.Path, str],\n",
    "                                          tiff_dir: Union[pathlib.Path, str],\n",
    "                                          chan_file: Union[pathlib.Path, str],\n",
    "                                          pixel_data_dir: Union[pathlib.Path, str],\n",
    "                                          pixel_cluster_col: str = 'pixel_meta_cluster',\n",
    "                                          sub_dir: str = None,\n",
    "                                          name_suffix: str = ''):\n",
    "    \"\"\"Generates pixel cluster masks and saves them for downstream analysis.\n",
    "\n",
    "    Args:\n",
    "        fovs (List[str]):\n",
    "            A list of fovs to generate and save pixel masks for.\n",
    "        base_dir (Union[pathlib.Path, str]):\n",
    "            The path to the data directory.\n",
    "        save_dir (Union[pathlib.Path, str]):\n",
    "            The directory to save the generated pixel cluster masks.\n",
    "        tiff_dir (Union[pathlib.Path, str]):\n",
    "            The path to the directory with the tiff data.\n",
    "        chan_file (Union[pathlib.Path, str]):\n",
    "            The path to the channel file inside each FOV folder (FOV folder as root).\n",
    "            Used to determine dimensions of the pixel mask.\n",
    "        pixel_data_dir (Union[pathlib.Path, str]):\n",
    "            The path to the data with full pixel data.\n",
    "            This data should also have the SOM and meta cluster labels appended.\n",
    "        pixel_cluster_col (str, optional):\n",
    "            The path to the data with full pixel data.\n",
    "            This data should also have the SOM and meta cluster labels appended.\n",
    "            Defaults to 'pixel_meta_cluster'.\n",
    "        sub_dir (str, optional):\n",
    "            The subdirectory to save the images in. If specified images are saved to\n",
    "            `\"data_dir/sub_dir\"`. If `sub_dir = None` the images are saved to `\"data_dir\"`.\n",
    "            Defaults to `None`.\n",
    "        name_suffix (str, optional):\n",
    "            Specify what to append at the end of every pixel mask. Defaults to `''`.\n",
    "    \"\"\"\n",
    "\n",
    "    # create the pixel cluster masks across each fov\n",
    "    with tqdm(total=len(fovs), desc=\"Pixel Cluster Mask Generation\") as pixel_mask_progress:\n",
    "        for fov in fovs:\n",
    "            # define the path to provided channel file in the fov dir, used to calculate dimensions\n",
    "            chan_file_path = os.path.join(fov, chan_file)\n",
    "\n",
    "            # generate the pixel mask for the FOV\n",
    "            pixel_mask: np.ndarray =\\\n",
    "                generate_pixel_cluster_mask(fov=fov, base_dir=base_dir, tiff_dir=tiff_dir,\n",
    "                                            chan_file_path=chan_file_path,\n",
    "                                            pixel_data_dir=pixel_data_dir,\n",
    "                                            pixel_cluster_col=pixel_cluster_col)\n",
    "\n",
    "            # save the pixel mask generated\n",
    "            data_utils.save_fov_mask(fov, data_dir=save_dir, mask_data=pixel_mask, sub_dir=sub_dir,\n",
    "                          name_suffix=name_suffix)\n",
    "\n",
    "            pixel_mask_progress.update(1)\n",
    "\n",
    "\n",
    "def generate_pixel_cluster_mask(fov, base_dir, tiff_dir, chan_file_path,\n",
    "                                pixel_data_dir, pixel_cluster_col='pixel_meta_cluster'):\n",
    "    \"\"\"For a fov, create a mask labeling each pixel with their SOM or meta cluster label\n",
    "\n",
    "    Args:\n",
    "        fov (list):\n",
    "            The fov to relabel\n",
    "        base_dir (str):\n",
    "            The path to the data directory\n",
    "        tiff_dir (str):\n",
    "            The path to the tiff data\n",
    "        chan_file_path (str):\n",
    "            The path to the sample channel file to load (`tiff_dir` as root).\n",
    "            Used to determine dimensions of the pixel mask.\n",
    "        pixel_data_dir (str):\n",
    "            The path to the data with full pixel data.\n",
    "            This data should also have the SOM and meta cluster labels appended.\n",
    "        pixel_cluster_col (str):\n",
    "            Whether to assign SOM or meta clusters\n",
    "            needs to be `'pixel_som_cluster'` or `'pixel_meta_cluster'`\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray:\n",
    "            The image overlaid with pixel cluster labels\n",
    "    \"\"\"\n",
    "\n",
    "    # path checking\n",
    "    io_utils.validate_paths([tiff_dir, os.path.join(tiff_dir, chan_file_path),\n",
    "                             os.path.join(base_dir, pixel_data_dir)])\n",
    "\n",
    "    # verify the pixel_cluster_col provided is valid\n",
    "    misc_utils.verify_in_list(\n",
    "        provided_cluster_col=[pixel_cluster_col],\n",
    "        valid_cluster_cols=['pixel_som_cluster', 'pixel_meta_cluster']\n",
    "    )\n",
    "\n",
    "    # verify the fov is valid\n",
    "    misc_utils.verify_in_list(\n",
    "        provided_fov_file=[fov + '.feather'],\n",
    "        consensus_fov_files=os.listdir(os.path.join(base_dir, pixel_data_dir))\n",
    "    )\n",
    "\n",
    "    # read the sample channel file to determine size of pixel cluster mask\n",
    "    channel_data = np.squeeze(imread(os.path.join(tiff_dir, chan_file_path)))\n",
    "\n",
    "    # define an array to hold the overlays for the fov\n",
    "    # use int16 to allow for Photoshop loading\n",
    "    img_data = np.zeros((channel_data.shape[0], channel_data.shape[1]), dtype='int16')\n",
    "\n",
    "    fov_data = feather.read_dataframe(\n",
    "        os.path.join(base_dir, pixel_data_dir, fov + '.feather')\n",
    "    )\n",
    "\n",
    "    # ensure integer display and not float\n",
    "    fov_data[pixel_cluster_col] = fov_data[pixel_cluster_col].astype(int)\n",
    "\n",
    "    # get the pixel coordinates\n",
    "    x_coords = fov_data['row_index'].values\n",
    "    y_coords = fov_data['column_index'].values\n",
    "\n",
    "    # convert to 1D indexing\n",
    "    coordinates = x_coords * img_data.shape[1] + y_coords\n",
    "\n",
    "    # get the cooresponding cluster labels for each pixel\n",
    "    cluster_labels = list(fov_data[pixel_cluster_col])\n",
    "\n",
    "    # assign each coordinate in pixel_cluster_mask to its respective cluster label\n",
    "    img_subset = img_data.ravel()\n",
    "    img_subset[coordinates] = cluster_labels\n",
    "    img_data = img_subset.reshape(img_data.shape)\n",
    "\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f456f215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class C:\n",
    "    pass\n",
    "args = C()\n",
    "args.output_dir = \"../output/\"\n",
    "args.name = \"region\"\n",
    "args.proportion = 0.05\n",
    "args.smoothing_channels = None\n",
    "args.smoothing_factor = 6\n",
    "args.blur_factor = 2\n",
    "args.filter_channels = None\n",
    "args.max_k = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29342f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "print()\n",
    "print(\"Running Pixel Classification...\")\n",
    "print()\n",
    "print(\"######################################################################################\")     \n",
    "print(\"Output directory = %s\" % args.output_dir)\n",
    "print(\"Name = %s\" % args.name)\n",
    "samples = os.listdir(os.path.join(args.output_dir, \"input\")) ################## !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#samples = [samples[18]]  ################## !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "print(\"Samples = %s\" % samples)\n",
    "print(\"Proportion = %s\" % args.proportion)\n",
    "print(\"Blur factor = %s\" % args.blur_factor)\n",
    "print(\"Smoothing factor = %s\" % args.smoothing_factor)\n",
    "print(\"Maximum K = %s\" % args.max_k)\n",
    "\n",
    "\n",
    "segmentation_dir = os.path.join(args.output_dir, \"segmentation\")\n",
    "cell_table_dir = os.path.join(args.output_dir, \"cell_table\")\n",
    "\n",
    "if args.smoothing_channels is not None:\n",
    "    smoothing_channels = [str(s.strip()) for s in args.smoothing_channels.split(\",\")]\n",
    "else:\n",
    "    smoothing_channels = None\n",
    "\n",
    "if args.filter_channels is not None:\n",
    "        filter_channels = parse_vars(args.filter_channels, \"bool\")\n",
    "else:\n",
    "    filter_channels = None\n",
    "\n",
    "print(\"Smoothing channels = %s\" % smoothing_channels)\n",
    "print(\"Filter background for channels = %s\" % filter_channels)\n",
    "print(\"######################################################################################\")    \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe133a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import feather\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import rc_file_defaults\n",
    "from alpineer import io_utils, load_utils\n",
    "from ark.analysis import visualize\n",
    "from ark.phenotyping import pixel_cluster_utils\n",
    "from ark.phenotyping.pixel_cluster_utils import find_fovs_missing_col\n",
    "from ark.utils import data_utils, example_dataset, plot_utils\n",
    "from ark.utils.metacluster_remap_gui import (MetaClusterData, MetaClusterGui,\n",
    "                                             colormap_helper,\n",
    "                                             metaclusterdata_from_files)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b666cdb-e0f1-4761-9d6a-d8f9822df1f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ark.phenotyping import pixel_som_clustering\n",
    "from ark.phenotyping.pixie_preprocessing import  create_pixel_matrix\n",
    "import ark.phenotyping.pixel_som_clustering as psc\n",
    "import ark.phenotyping.pixel_cluster_utils as pcu\n",
    "import ark.phenotyping.pixel_meta_clustering as pmc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c98275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ark.phenotyping.pixel_meta_clustering import apply_pixel_meta_cluster_remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ark.phenotyping.pixel_meta_clustering import generate_remap_avg_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d1e3e-877f-428b-a443-f0640148b13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "tiff_dir = os.path.join(args.output_dir, \"input\")\n",
    "img_sub_folder = None\n",
    "seg_suffix = '_whole_cell.tiff'\n",
    "\n",
    "# set to True to turn on multiprocessing\n",
    "multiprocess = False\n",
    "\n",
    "# define the number of samples to process in parallel, ignored if multiprocessing is set to False\n",
    "batch_size = 5\n",
    "\n",
    "pixel_cluster_prefix = args.name\n",
    "\n",
    "# define the base output pixel folder using the specified pixel cluster prefix\n",
    "pixel_output_dir = os.path.join(\"pixie\", \"%s_pixel_output_dir\" % pixel_cluster_prefix)\n",
    "if not os.path.exists(os.path.join(args.output_dir, pixel_output_dir)):\n",
    "    os.makedirs(os.path.join(args.output_dir, pixel_output_dir))\n",
    " \n",
    "# define the preprocessed pixel data folders\n",
    "pixel_data_dir = os.path.join(pixel_output_dir, 'pixel_mat_data')\n",
    "pixel_subset_dir = os.path.join(pixel_output_dir, 'pixel_mat_subset')\n",
    "norm_vals_name = os.path.join(pixel_output_dir, 'channel_norm_post_rowsum.feather')\n",
    "pixel_som_weights_name = os.path.join(pixel_output_dir, 'pixel_som_weights.feather')\n",
    "pc_chan_avg_som_cluster_name = os.path.join(pixel_output_dir, 'pixel_channel_avg_som_cluster.csv')\n",
    "pc_chan_avg_meta_cluster_name = os.path.join(pixel_output_dir, 'pixel_channel_avg_meta_cluster.csv')\n",
    "pixel_meta_cluster_remap_name = os.path.join(pixel_output_dir, 'pixel_meta_cluster_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67864273-135d-44c2-a131-edf27d0ddd08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0977b78-cc18-49d6-9ac6-0ad2fd1fdc71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# channels = io_utils.list_files(os.path.join(tiff_dir, samples[0]), substrs=['.tiff'])\n",
    "# channels = [s.replace('.tiff', '') for s in channels]\n",
    "# channels = np.array(channels, dtype='<U32')\n",
    "print(\"Smoothing markers...\")\n",
    "# set an optional list of markers for additional blurring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc430b5b-677a-41a3-afd9-de4d670964e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channels_metadata = pd.read_csv(os.path.join(args.output_dir, \"..\", \"annotation\", \"marker_metadata.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedbf01b-c7dd-4060-b2f0-187e91b4d8d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "channels = channels_metadata.Marker[channels_metadata.UseForRegionPixelClustering].tolist()\n",
    "print(\"Channels:\")\n",
    "print(channels)\n",
    "channels = np.array(channels, dtype='<U32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6964e20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1058f343-bd75-4d38-b37d-d0addd060eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smoothing_channels = channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62faf40c-5328-49bd-90eb-146074bf7c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if smoothing_channels is not None:\n",
    "    pixel_cluster_utils.smooth_channels(\n",
    "        fovs=samples,\n",
    "        tiff_dir=tiff_dir,\n",
    "        img_sub_folder=img_sub_folder,\n",
    "        channels=smoothing_channels,\n",
    "        smooth_vals=args.smoothing_factor\n",
    "    )\n",
    "    mask = np.isin(channels, smoothing_channels)\n",
    "    channels[mask] = np.char.add(channels[mask], \"_smoothed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159130d7-2d48-4875-86e6-eec91fb667b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smoothing_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4102d960-28e2-4808-af7d-556f4de2171c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filter_channels_list = channels_metadata.KeepOutsideNucleus[channels_metadata.UseForPixelClustering].tolist()\n",
    "#n = 0\n",
    "#filter_channels = dict()\n",
    "#for i in channels:\n",
    "#    if filter_channels_list[n] != \"None\":\n",
    "#        filter_channels[channels[n]] = filter_channels_list[n]\n",
    "#    n = n+1 \n",
    "#filter_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755703d-99fc-48c3-8407-3b529a2a2848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef0153-edba-466b-9967-290622f95ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Filtering background for markers...\")\n",
    "if filter_channels is not None:\n",
    "    for channel in filter_channels:\n",
    "        for samp in samples:\n",
    "            nuclear_exclude = filter_channels[channel] == 'True'\n",
    "            filter_with_nuclear_mask(\n",
    "                fovs=[samp],\n",
    "                tiff_dir=tiff_dir,\n",
    "                seg_dir = segmentation_dir,\n",
    "                channel = channel,\n",
    "                nuc_seg_suffix=\"_nuclear.tiff\",\n",
    "                img_sub_folder = img_sub_folder,\n",
    "                exclude=nuclear_exclude\n",
    "            )\n",
    "            if nuclear_exclude == True:\n",
    "                mask = np.isin(channels, channel)\n",
    "                channels[mask] = np.char.add(channels[mask], \"_nuc_exclude\")\n",
    "            else:\n",
    "                mask = np.isin(channels, channel)\n",
    "                channels[mask] = np.char.add(channels[mask], \"_nuc_include\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ceb654-9bc6-4b22-9bf9-4d3e44739357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Creating Pixel Matrix...\")\n",
    "\n",
    "# run pixel data preprocessing\n",
    "create_pixel_matrix(\n",
    "    samples,\n",
    "    channels,\n",
    "    args.output_dir,\n",
    "    tiff_dir,\n",
    "    segmentation_dir,\n",
    "    img_sub_folder=img_sub_folder,\n",
    "    seg_suffix=seg_suffix,\n",
    "    pixel_output_dir=pixel_output_dir,\n",
    "    data_dir=pixel_data_dir,\n",
    "    subset_dir=pixel_subset_dir,\n",
    "    norm_vals_name=norm_vals_name,\n",
    "    blur_factor=args.blur_factor,\n",
    "    subset_proportion=args.proportion,\n",
    "    multiprocess=multiprocess,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(\"Training SOM Pixel clustering\")\n",
    "\n",
    "# create the pixel-level SOM weights\n",
    "pixel_pysom = pixel_som_clustering.train_pixel_som(  \n",
    "    samples,\n",
    "    channels.tolist(),\n",
    "    args.output_dir,\n",
    "    subset_dir=pixel_subset_dir,\n",
    "    norm_vals_name=norm_vals_name,\n",
    "    som_weights_name=pixel_som_weights_name,\n",
    "    num_passes=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# use pixel SOM weights to assign pixel clusters\n",
    "pixel_som_clustering.cluster_pixels(\n",
    "    samples,\n",
    "    channels.tolist(),\n",
    "    args.output_dir,\n",
    "    pixel_pysom,\n",
    "    data_dir=pixel_data_dir,\n",
    "    multiprocess=multiprocess,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# generate the SOM cluster summary files\n",
    "pixel_som_clustering.generate_som_avg_files(\n",
    "    samples,\n",
    "    channels.tolist(),\n",
    "    args.output_dir,\n",
    "    pixel_pysom,\n",
    "    data_dir=pixel_data_dir,\n",
    "    pc_chan_avg_som_cluster_name=pc_chan_avg_som_cluster_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f34cb-4565-4fae-8d99-30acc9a65b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d372a07e-7ade-49a7-b83e-ceb71c830128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Run pixel consensus clustering\")\n",
    "cap = 3\n",
    "\n",
    "# Forcing re-running of consensus clustering as if not \"pixel_cc\" is not initialized\n",
    "fovs_list = find_fovs_missing_col(args.output_dir, pixel_data_dir, 'pixel_meta_cluster')\n",
    "\n",
    "if len(fovs_list) == 0:\n",
    "    data_path = os.path.join(args.output_dir, pixel_data_dir)\n",
    "    fov_files = io_utils.list_files(data_path, substrs='.feather')\n",
    "    for file in fov_files:\n",
    "        fov_data = feather.read_dataframe(os.path.join(data_path, file))\n",
    "        fov_data = fov_data.drop('pixel_meta_cluster', axis=1)\n",
    "        feather.write_dataframe(df= fov_data, dest= os.path.join(data_path, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5289696-11ae-47a8-82c1-cc3c7133a838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf30d79a-20e3-4bf7-a1c4-ac53e6c09197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run hierarchical clustering based on pixel SOM cluster assignments\n",
    "pixel_cc = pmc.pixel_consensus_cluster(\n",
    "    samples,\n",
    "    channels.tolist(),\n",
    "    args.output_dir,\n",
    "    max_k=args.max_k,\n",
    "    cap=cap,\n",
    "    data_dir=pixel_data_dir,\n",
    "    pc_chan_avg_som_cluster_name=pc_chan_avg_som_cluster_name,\n",
    "    multiprocess=multiprocess,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "# generate the meta cluster summary files\n",
    "pmc.generate_meta_avg_files(\n",
    "    samples,\n",
    "    channels.tolist(),\n",
    "    args.output_dir,\n",
    "    pixel_cc,\n",
    "    data_dir=pixel_data_dir,\n",
    "    pc_chan_avg_som_cluster_name=pc_chan_avg_som_cluster_name,\n",
    "    pc_chan_avg_meta_cluster_name=pc_chan_avg_meta_cluster_name\n",
    ")\n",
    "\n",
    "# Adding column for later\n",
    "data_path = os.path.join(args.output_dir, pixel_data_dir)\n",
    "fov_files = io_utils.list_files(data_path, substrs='.feather')\n",
    "for file in fov_files:\n",
    "    fov_data = feather.read_dataframe(os.path.join(data_path, file))\n",
    "    fov_data[\"pixel_meta_cluster_rename\"] = fov_data[\"pixel_meta_cluster\"]\n",
    "    feather.write_dataframe(df= fov_data, dest= os.path.join(data_path, file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660bdd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_chan_avg_som_cluster_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "print(\"Plotting Heatmap\")\n",
    "# Heatmap\n",
    "rc_file_defaults()\n",
    "plt.ion()\n",
    "\n",
    "pixel_mcd = metaclusterdata_from_files(\n",
    "    os.path.join(args.output_dir, pc_chan_avg_som_cluster_name),\n",
    "    cluster_type='pixel'\n",
    ")\n",
    "pixel_mcd.output_mapping_filename = os.path.join(args.output_dir, pixel_meta_cluster_remap_name)\n",
    "pixel_mcg = MetaClusterGui(pixel_mcd, width=10,  enable_throttle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560552ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_mcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2949a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_meta_cluster_remap_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5591f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_remap_avg_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e6b7f-f10b-42df-b9aa-161398f013e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IF not running the remapping:\n",
    "#df = pd.DataFrame(pixel_mcd.mapping)\n",
    "#df[\"mc_name\"] = df['metacluster']\n",
    "\n",
    "#df2 = df.copy()\n",
    "#df2.columns = ['pixel_meta_cluster', 'pixel_meta_cluster_rename']\n",
    "#df2.index.name = \"pixel_som_cluster\"\n",
    "#df2.reset_index(inplace=True)\n",
    "#df2.to_csv( os.path.join(args.output_dir, pixel_meta_cluster_remap_name), index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91200ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cf69a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the meta cluster values in the pixel dataset\n",
    "apply_pixel_meta_cluster_remapping(\n",
    "    samples,\n",
    "    channels,\n",
    "    args.output_dir,\n",
    "    pixel_data_dir,\n",
    "    pixel_meta_cluster_remap_name,\n",
    "    multiprocess=multiprocess,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad08c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recompute the mean channel expression per meta cluster and apply these new names to the SOM cluster average data\n",
    "generate_remap_avg_files(\n",
    "    samples,\n",
    "    smoothing_channels,\n",
    "    args.output_dir,\n",
    "    pixel_data_dir,\n",
    "    pixel_meta_cluster_remap_name,\n",
    "    pc_chan_avg_som_cluster_name,\n",
    "    pc_chan_avg_meta_cluster_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddc571",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cmap, _ = colormap_helper.generate_meta_cluster_colormap_dict(\n",
    "    os.path.join(args.output_dir, pixel_meta_cluster_remap_name),\n",
    "    pixel_mcg.im_cl.cmap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103965ae-c94b-470a-996b-b8fa33daf609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset_pixel_fovs = samples\n",
    "\n",
    "print(\"Generating pixel masks...\")\n",
    "# define the path to the channel file\n",
    "if img_sub_folder is None:\n",
    "    chan_file = os.path.join(\n",
    "        io_utils.list_files(os.path.join(tiff_dir, samples[0]), substrs=['.tiff'])[0]\n",
    "    )\n",
    "else:\n",
    "    chan_file = os.path.join(\n",
    "        img_sub_folder, io_utils.list_files(os.path.join(tiff_dir, samples[0], img_sub_folder), substrs=['.tiff'])[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756cb402-ad12-4d6b-aa94-9edcee246feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_and_save_pixel_cluster_masks(\n",
    "    fovs=subset_pixel_fovs,\n",
    "    base_dir=args.output_dir,\n",
    "    save_dir=os.path.join(args.output_dir, pixel_output_dir),\n",
    "    tiff_dir=tiff_dir,\n",
    "    chan_file=chan_file,\n",
    "    pixel_data_dir=pixel_data_dir,\n",
    "    pixel_cluster_col='pixel_meta_cluster',\n",
    "    sub_dir='pixel_masks',\n",
    "    name_suffix='_pixel_mask',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b43b3-6050-4f1d-ac12-0b7589c8af64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pixel_fov in subset_pixel_fovs:\n",
    "    pixel_cluster_mask = load_utils.load_imgs_from_dir(\n",
    "        data_dir=os.path.join(args.output_dir, pixel_output_dir, \"pixel_masks\"),\n",
    "        files=[pixel_fov + \"_pixel_mask.tiff\"],\n",
    "        trim_suffix=\"_pixel_mask\",\n",
    "        match_substring=\"_pixel_mask\",\n",
    "        xr_dim_name=\"pixel_mask\",\n",
    "        xr_channel_names=None,\n",
    "    )\n",
    "\n",
    "    plot_utils.plot_pixel_cell_cluster_overlay(\n",
    "        pixel_cluster_mask,\n",
    "        [pixel_fov],\n",
    "        os.path.join(args.output_dir, pixel_meta_cluster_remap_name),\n",
    "        metacluster_colors = raw_cmap\n",
    "    )\n",
    "    plt.savefig(os.path.join(args.output_dir, pixel_output_dir, \"pixel_masks\", pixel_fov + \"_overlay_meta_clusters\" +'.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4acfa6d-9c2b-4026-a979-c8da6e4c6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the params dict\n",
    "cell_clustering_params = {\n",
    "    'fovs': io_utils.remove_file_extensions(io_utils.list_files(os.path.join(args.output_dir, pixel_data_dir), substrs='.feather')),\n",
    "    'channels': channels.tolist(),\n",
    "    'segmentation_dir': segmentation_dir,\n",
    "    'seg_suffix': seg_suffix,\n",
    "    'pixel_data_dir': pixel_data_dir,\n",
    "    'pc_chan_avg_som_cluster_name': pc_chan_avg_som_cluster_name,\n",
    "    'pc_chan_avg_meta_cluster_name': pc_chan_avg_meta_cluster_name\n",
    "}\n",
    "\n",
    "# save the params dict\n",
    "with open(os.path.join(args.output_dir, pixel_output_dir, 'cell_clustering_params.json'), 'w') as fh:\n",
    "    json.dump(cell_clustering_params, fh)\n",
    "    \n",
    "print('Finished Running Pixel Classification in %s seconds', round(time.time() - start_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d9930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
